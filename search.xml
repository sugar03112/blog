<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>DDPM</title>
      <link href="/2025/04/16/DDPM/"/>
      <url>/2025/04/16/DDPM/</url>
      
        <content type="html"><![CDATA[<h1 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h1><p>$ x $为数据，即图像<br>$ x_t $为该图像在t时刻（状态）的图像<br>$ \epsilon~\sim~N(0,1) $ 高斯噪声，即在标准高斯分布下进行的随机采样</p><h1 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h1><p>图像不断加入噪声的过程:</p><script type="math/tex; mode=display">x_t = \sqrt{\beta_t} \times \epsilon_t + \sqrt{1-\beta_t} \times x_{t-1}</script><p>显然，这样一个迭代过程是从 $x_0$ 出发的，也就是说任意状态下的图片 $ x_t $ 都可以由 $x_0$ 产生<br>设</p><script type="math/tex; mode=display">\alpha_t = 1-\beta_t</script><script type="math/tex; mode=display">\overline{\alpha_t}=\prod^t_{i=1}\alpha_i</script><p>由此化简为</p><script type="math/tex; mode=display">x_t=\sqrt{1-\overline{\alpha_t}}\times\epsilon+\sqrt{\overline{\alpha_t}}\times x_0</script><p>同时可得一些恒等变换：<br>    $\epsilon = \frac{x_t-\sqrt{\overline{\alpha_t}}x_0}{\sqrt{1-\overline{\alpha}_t}}$<br>    $x_0 = \frac{1}{\sqrt{\overline{\alpha}_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\times \epsilon)$</p><p>先验：</p><script type="math/tex; mode=display">p_{\theta}(x_{t-1}|x_t)=N(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))</script><p>后验：</p><script type="math/tex; mode=display">q(x_t|x_0)=N(x_t;\sqrt{\overline{\alpha_t}}~x_0,(1-\overline{\alpha_t})I)</script><p>随机变量$x_t$遵从这样的高斯分布。</p><h1 id="反向过程"><a href="#反向过程" class="headerlink" title="反向过程"></a>反向过程</h1><p>图像去噪生成的过程：<br>后验：</p><script type="math/tex; mode=display">q(x_{t-1}|x_t,x_0)=\frac{q(x_{t}|x_{t-1},x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)}</script><p>根据贝叶斯定理可以得出上式，等式右侧均为高斯分布，由此可根据高斯分布表达式代入，得出解析函数，根据计算得</p><script type="math/tex; mode=display">q(x_{t-1}|x_t,x_0)\sim N(\frac{\sqrt(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}(1-{\alpha_t})}{1-\overline{\alpha_t}}\times \frac{x_t-\sqrt{1-\overline{\alpha}_t}\times \epsilon}{\sqrt {\overline{\alpha}_t}}~,~(\sqrt{\frac{\beta_t(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t}})^2)</script><p> 其中q的均值为：</p><script type="math/tex; mode=display">\widetilde{\mu}_t(x_t,x_0) = \frac{\sqrt(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0</script><p>训练时让模型去预测噪声$\epsilon$，记作$\epsilon_{\theta}(x_t,t)$<br>将$x_0$代入后，也就得到了前面$q$的高斯分布中的等式，即</p><script type="math/tex; mode=display">\mu_{\theta}(x_t,x_0) = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}}\times \epsilon_{\theta}(x_t,t))</script><p>但这样我们只的到了一个确定的$\mu_{\theta}$，而本身这个过程是一个推算概率分布的过程，它具有不确定性，因此需要在高斯分布中再次采样，以保持采样过程的随机性，以生成不同的样本。</p><h2 id="重参数化"><a href="#重参数化" class="headerlink" title="重参数化"></a>重参数化</h2><p>现在我们指导反向过程还是高斯分布，我们便利用这个均值做一个标准正态采样</p><script type="math/tex; mode=display">x_{t-1} = \mu_{\theta}(x_t,t)+\sigma_tz~,~~~~z\sim N(0,1)</script><p>因此整合之后便得到了</p><script type="math/tex; mode=display">x_{t-1} = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}}\times \epsilon_{\theta}(x_t,t))+\sigma_{t}z</script><p>其中$\sigma_t=\widetilde{\beta}_t$ .</p><h1 id="复现代码"><a href="#复现代码" class="headerlink" title="复现代码"></a>复现代码</h1><p>以下是复现的代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from torchvision import datasets, transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line">def show_images(data, num_samples=16, cols=16):</span><br><span class="line">    plt.figure(figsize=(15, 15))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_samples):</span><br><span class="line">        img, label = data[i]  <span class="comment"># 获取图像和标签</span></span><br><span class="line">        img = img.permute(1, 2, 0).numpy()  <span class="comment"># (C, H, W) -&gt; (H, W, C)</span></span><br><span class="line">        plt.subplot(int(num_samples / cols + 1), cols, i + 1)</span><br><span class="line">        plt.imshow(img)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line">  </span><br><span class="line">root = <span class="string">&quot;/kaggle/input/cifar10-python&quot;</span></span><br><span class="line">  </span><br><span class="line">train_dataset = datasets.CIFAR10(root, train=True, download=True,transform=transforms.ToTensor())</span><br><span class="line">train_dataLoader = DataLoader(train_dataset, batch_size=3000, shuffle=True)</span><br><span class="line">test_dataset = datasets.CIFAR10(root, train=False, download=True,transform=transforms.ToTensor())</span><br><span class="line">test_dataLoader = DataLoader(test_dataset, batch_size=3000, shuffle=True)</span><br><span class="line">show_images(train_dataset)</span><br><span class="line">show_images(test_dataset)</span><br><span class="line">  </span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">  </span><br><span class="line">def linear_beta_schedule(timesteps, start=0.0001, end = 0.02):</span><br><span class="line">    <span class="built_in">return</span> torch.linspace(start, end, timesteps)</span><br><span class="line"><span class="comment">#根据时间步 t 从一个值列表 vals 中获取对应的值，并对输出形状进行 reshape 以匹配输入张量的维度结构 x_shape</span></span><br><span class="line">def get_index_from_list(vals, t, x_shape):</span><br><span class="line">    batch_size = t.shape[0]</span><br><span class="line">    out = vals.gather(-1, t.cpu())</span><br><span class="line">    <span class="built_in">return</span> out.reshape(batch_size, *((<span class="number">1</span>,)*(len(x_shape) - <span class="number">1</span>))).to(t.device)</span><br><span class="line"><span class="comment">#接受一个图像和一个时间步长作为输入，并返回它的噪声版本</span></span><br><span class="line">def forward_diffusion_sample(x_0, t ,device=device):</span><br><span class="line">    x_0.to(device)</span><br><span class="line">    noise = torch.randn_like(x_0)</span><br><span class="line">    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)</span><br><span class="line">    sqrt_one_minus_alphas_cumprod_t=get_index_from_list(sqrt_one_minus_alphas_cumprod, t, x_0.shape)</span><br><span class="line">    <span class="built_in">return</span> sqrt_alphas_cumprod_t.to(device)*x_0.to(device)\</span><br><span class="line">    +sqrt_one_minus_alphas_cumprod_t.to(device)*noise.to(device), noise.to(device)</span><br><span class="line">  </span><br><span class="line">T=300</span><br><span class="line">betas = linear_beta_schedule(timesteps=T)</span><br><span class="line">  </span><br><span class="line">alphas = 1.-betas</span><br><span class="line">alphas_cumprod = torch.cumprod(alphas, axis=0)</span><br><span class="line">alphas_cumprod_prev = F.pad(alphas_cumprod[:-1],(1,0),value=1.0)</span><br><span class="line">sqrt_recip_alphas= torch.sqrt(1.0/alphas)</span><br><span class="line">sqrt_alphas_cumprod=torch.sqrt(alphas_cumprod)</span><br><span class="line">sqrt_one_minus_alphas_cumprod = torch.sqrt(1.-alphas_cumprod)</span><br><span class="line">posterior_variance = betas * (1. - alphas_cumprod_prev)/(1. - alphas_cumprod)</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from torchvision import datasets, transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import numpy as np</span><br><span class="line">  </span><br><span class="line">img_size = 64</span><br><span class="line">batch_size =128</span><br><span class="line">def load_transformed_dataset():</span><br><span class="line">    data_transforms=[</span><br><span class="line">        transforms.Resize((img_size,img_size)),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Lambda(lambda t:(t*2)-1)</span><br><span class="line">    ]</span><br><span class="line">    data_transform = transforms.Compose(data_transforms)</span><br><span class="line">    train = datasets.CIFAR10(root, train=True, download=True,transform=data_transform)</span><br><span class="line">    <span class="built_in">test</span> = datasets.CIFAR10(root, train=False, download=False,transform=data_transform)</span><br><span class="line">    <span class="built_in">return</span> torch.utils.data.ConcatDataset([train,<span class="built_in">test</span>])</span><br><span class="line">def show_tensor_image(image):</span><br><span class="line">    reverse_transforms = transforms.Compose([</span><br><span class="line">        transforms.Lambda(lambda t:(t+1)/2),</span><br><span class="line">        transforms.Lambda(lambda t:t.permute(1,2,0)),</span><br><span class="line">        transforms.Lambda(lambda t:t*255.),</span><br><span class="line">        transforms.Lambda(lambda t:t.cpu().numpy().astype(np.uint8)),</span><br><span class="line">        transforms.ToPILImage(),</span><br><span class="line">    ])</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> len(image.shape)==4:</span><br><span class="line">        image = image[0,:,:,:]</span><br><span class="line">    plt.imshow(reverse_transforms(image))</span><br><span class="line">root = <span class="string">&quot;/root/autodl-fs/cifar-10-python&quot;</span></span><br><span class="line">data = load_transformed_dataset()</span><br><span class="line">dataloader = DataLoader(data, batch_size, shuffle=True, drop_last=True)</span><br><span class="line">  </span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">image = next(iter(dataloader))[0]</span><br><span class="line">  </span><br><span class="line">plt.figure(figsize=(15,15))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">num_images = 10</span><br><span class="line">stepsize = int(T/num_images)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> range(0, T, stepsize):</span><br><span class="line">    t = torch.Tensor([idx]).<span class="built_in">type</span>(torch.int64)</span><br><span class="line">    plt.subplot(1, num_images+1, int(idx/stepsize)+1)</span><br><span class="line">    image, noise = forward_diffusion_sample(image, t)</span><br><span class="line">    show_tensor_image(image)</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">&quot;diffusion_process.png&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Saved to diffusion_process.png&quot;</span>)</span><br><span class="line">  </span><br><span class="line">from torch import nn</span><br><span class="line">import math</span><br><span class="line">  </span><br><span class="line">class Block(nn.Module):</span><br><span class="line">    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.time_mlp = nn.Linear(time_emb_dim, out_ch)</span><br><span class="line">        <span class="keyword">if</span> up:</span><br><span class="line">            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)</span><br><span class="line">            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)</span><br><span class="line">            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)</span><br><span class="line">        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)</span><br><span class="line">        self.bnorm1 = nn.BatchNorm2d(out_ch)</span><br><span class="line">        self.bnorm2 = nn.BatchNorm2d(out_ch)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">  </span><br><span class="line">    def forward(self, x, t, ):</span><br><span class="line">        h = self.bnorm1(self.relu(self.conv1(x)))</span><br><span class="line">        time_emb = self.relu(self.time_mlp(t))</span><br><span class="line">        time_emb = time_emb[(..., )+(None, )*2]</span><br><span class="line">        h = h+time_emb</span><br><span class="line">        h = self.bnorm2(self.relu(self.conv2(h)))</span><br><span class="line">        <span class="built_in">return</span> self.transform(h)</span><br><span class="line">  </span><br><span class="line">class SinusoidalPositionEmbeddings(nn.Module):</span><br><span class="line">    def __init__(self, dim):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">  </span><br><span class="line">    def forward(self, <span class="keyword">time</span>):</span><br><span class="line">        device = time.device</span><br><span class="line">        half_dim = self.dim //2</span><br><span class="line">        embeddings = math.log(10000)/(half_dim - 1)</span><br><span class="line">        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)</span><br><span class="line">        embeddings = <span class="keyword">time</span>[:,None]*embeddings[None, :]</span><br><span class="line">        embeddings = torch.cat((embeddings.sin(),embeddings.cos()), dim=1)</span><br><span class="line">        <span class="built_in">return</span> embeddings</span><br><span class="line">  </span><br><span class="line">class UNet(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        image_channels = 3</span><br><span class="line">        down_channels = (64, 128, 256, 512, 1024)</span><br><span class="line">        up_channels = (1024, 512, 256, 128, 64)</span><br><span class="line">        out_dim = 1</span><br><span class="line">        time_emb_dim = 32</span><br><span class="line">  </span><br><span class="line">        self.time_mlp = nn.Sequential(</span><br><span class="line">            SinusoidalPositionEmbeddings(time_emb_dim),</span><br><span class="line">            nn.Linear(time_emb_dim, time_emb_dim),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">  </span><br><span class="line">        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)</span><br><span class="line">        <span class="comment">#下采样</span></span><br><span class="line">        self.downs = nn.ModuleList([Block(down_channels[i],down_channels[i+1],time_emb_dim)\</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(down_channels)-1)])</span><br><span class="line">        <span class="comment">#上采样</span></span><br><span class="line">        self.ups = nn.ModuleList([Block(up_channels[i],up_channels[i+1],time_emb_dim,up=True)\</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(down_channels)-1)])</span><br><span class="line">        self.output = nn.Conv2d(up_channels[-1], 3, out_dim)</span><br><span class="line">    def forward(self, x, timestep):</span><br><span class="line">        t=self.time_mlp(timestep)</span><br><span class="line">        t.to(x.device)</span><br><span class="line">        x=self.conv0(x)</span><br><span class="line">        residual_inputs = []</span><br><span class="line">        <span class="keyword">for</span> down <span class="keyword">in</span> self.downs:</span><br><span class="line">            x = down(x,t)</span><br><span class="line">            residual_inputs.append(x)</span><br><span class="line">        <span class="keyword">for</span> up <span class="keyword">in</span> self.ups:</span><br><span class="line">            residual_x = residual_inputs.pop()</span><br><span class="line">            x = torch.cat((x,residual_x),dim=<span class="number">1</span>)</span><br><span class="line">            x=up(x,t)</span><br><span class="line">        return self.output(x)</span><br><span class="line">  </span><br><span class="line">model = UNet()</span><br><span class="line">print(&quot;Num params:&quot;, sum(p.numel() for p in model.parameters()))</span><br><span class="line"></span><br><span class="line">def get_loss(model, x_0, t):</span><br><span class="line">    x_noisy, noise = forward_diffusion_sample(x_0, t, device)</span><br><span class="line">    noise_pred = model(x_noisy, t)</span><br><span class="line">    noise_pred.to(device)</span><br><span class="line">    <span class="built_in">return</span> F.l1_loss(noise, noise_pred)</span><br><span class="line">  </span><br><span class="line">@torch.no_grad()</span><br><span class="line">def sample_timestep(x,t):</span><br><span class="line">    betas_t = get_index_from_list(betas, t, x.shape)</span><br><span class="line">    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod,t,x.shape)</span><br><span class="line">    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)</span><br><span class="line">  </span><br><span class="line">    model_mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t)</span><br><span class="line">    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> t==0:</span><br><span class="line">        <span class="built_in">return</span> model_mean</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        noise = torch.randn_like(x)</span><br><span class="line">        <span class="built_in">return</span> model_mean + torch.sqrt(posterior_variance_t)*noise</span><br><span class="line">  </span><br><span class="line">@torch.no_grad()</span><br><span class="line">def sample_plot_image():</span><br><span class="line">    Img_size=img_size</span><br><span class="line">    img = torch.randn((<span class="number">1</span>, <span class="number">3</span>, Img_size, Img_size),device=device)</span><br><span class="line">    plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    num_images=10</span><br><span class="line">    stepsize = int(T/num_images)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(0,T)[::-1]:</span><br><span class="line">        t = torch.full((<span class="number">1</span>,), i, device=device, dtype=torch.long)</span><br><span class="line">        img = sample_timestep(img,t)</span><br><span class="line">        if i %stepsize ==<span class="number">0</span>:</span><br><span class="line">            plt.subplot(<span class="number">1</span>,num_images, int(i/stepsize+<span class="number">1</span>))</span><br><span class="line">            show_tensor_image(img.detach().cpu())</span><br><span class="line">  </span><br><span class="line">from torch.optim import Adam</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">model.to(device)</span><br><span class="line">noise = noise.to(device)</span><br><span class="line">model = nn.DataParallel(model)</span><br><span class="line">optimizer = Adam(model.parameters(), lr=0.001)</span><br><span class="line">epochs = 100</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        t = torch.randint(0,T,(batch_size,),device=device).long()</span><br><span class="line">        loss=get_loss(model, batch[0],t)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> epoch % 1 ==0 and step == 0:</span><br><span class="line">            <span class="built_in">print</span>(f<span class="string">&quot;Epoch&#123;epoch&#125; | step &#123;step:03d&#125; loss: &#123;loss.item()&#125;&quot;</span>)</span><br><span class="line">            sample_plot_image()</span><br><span class="line">            plt.tight_layout()</span><br><span class="line">            plt.savefig(f<span class="string">&quot;diffusion_process_&#123;epoch&#125;.png&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(f<span class="string">&quot;Saved to diffusion_process_&#123;epoch&#125;.png&quot;</span>)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> notebook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/04/15/hello-world/"/>
      <url>/2025/04/15/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
