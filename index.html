<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="选择大于努力">
<meta property="og:type" content="website">
<meta property="og:title" content="小象的知识库">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="小象的知识库">
<meta property="og:description" content="选择大于努力">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="B.W. Xiang">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'zh-CN'
  };
</script>

  <title>小象的知识库</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/rss2.xml" title="小象的知识库" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">小象的知识库</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="archive fa-fw"></i>归档</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-resources">

    <a href="/resources/" rel="section"><i class="download fa-fw"></i>资源</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="sitemap fa-fw"></i>站点地图</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/16/DDPM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="B.W. Xiang">
      <meta itemprop="description" content="选择大于努力">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小象的知识库">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/04/16/DDPM/" class="post-title-link" itemprop="url">DDPM</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-04-16 00:20:45" itemprop="dateCreated datePublished" datetime="2025-04-16T00:20:45+08:00">2025-04-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-04-21 16:34:03" itemprop="dateModified" datetime="2025-04-21T16:34:03+08:00">2025-04-21</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h1><p>$ x $为数据，即图像<br>$ x_t $为该图像在t时刻（状态）的图像<br>$ \epsilon~\sim~N(0,1) $ 高斯噪声，即在标准高斯分布下进行的随机采样</p>
<h1 id="前向过程"><a href="#前向过程" class="headerlink" title="前向过程"></a>前向过程</h1><p>图像不断加入噪声的过程:</p>
<script type="math/tex; mode=display">x_t = \sqrt{\beta_t} \times \epsilon_t + \sqrt{1-\beta_t} \times x_{t-1}</script><p>显然，这样一个迭代过程是从 $x_0$ 出发的，也就是说任意状态下的图片 $ x_t $ 都可以由 $x_0$ 产生<br>设</p>
<script type="math/tex; mode=display">\alpha_t = 1-\beta_t</script><script type="math/tex; mode=display">\overline{\alpha_t}=\prod^t_{i=1}\alpha_i</script><p>由此化简为</p>
<script type="math/tex; mode=display">x_t=\sqrt{1-\overline{\alpha_t}}\times\epsilon+\sqrt{\overline{\alpha_t}}\times x_0</script><p>同时可得一些恒等变换：<br>    $\epsilon = \frac{x_t-\sqrt{\overline{\alpha_t}}x_0}{\sqrt{1-\overline{\alpha}_t}}$<br>    $x_0 = \frac{1}{\sqrt{\overline{\alpha}_t}}(x_t-\sqrt{1-\overline{\alpha}_t}\times \epsilon)$</p>
<p>先验：</p>
<script type="math/tex; mode=display">p_{\theta}(x_{t-1}|x_t)=N(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))</script><p>后验：</p>
<script type="math/tex; mode=display">q(x_t|x_0)=N(x_t;\sqrt{\overline{\alpha_t}}~x_0,(1-\overline{\alpha_t})I)</script><p>随机变量$x_t$遵从这样的高斯分布。</p>
<h1 id="反向过程"><a href="#反向过程" class="headerlink" title="反向过程"></a>反向过程</h1><p>图像去噪生成的过程：<br>后验：</p>
<script type="math/tex; mode=display">q(x_{t-1}|x_t,x_0)=\frac{q(x_{t}|x_{t-1},x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)}</script><p>根据贝叶斯定理可以得出上式，等式右侧均为高斯分布，由此可根据高斯分布表达式代入，得出解析函数，根据计算得</p>
<script type="math/tex; mode=display">q(x_{t-1}|x_t,x_0)\sim N(\frac{\sqrt(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}(1-{\alpha_t})}{1-\overline{\alpha_t}}\times \frac{x_t-\sqrt{1-\overline{\alpha}_t}\times \epsilon}{\sqrt {\overline{\alpha}_t}}~,~(\sqrt{\frac{\beta_t(1-\overline{\alpha}_{t-1})}{1-\overline{\alpha}_t}})^2)</script><p> 其中q的均值为：</p>
<script type="math/tex; mode=display">\widetilde{\mu}_t(x_t,x_0) = \frac{\sqrt(1-\overline{\alpha_{t-1}})}{1-\overline{\alpha_{t}}}x_t+\frac{\sqrt{\overline{\alpha_{t-1}}}\beta_t}{1-\overline{\alpha_t}}x_0</script><p>训练时让模型去预测噪声$\epsilon$，记作$\epsilon_{\theta}(x_t,t)$<br>将$x_0$代入后，也就得到了前面$q$的高斯分布中的等式，即</p>
<script type="math/tex; mode=display">\mu_{\theta}(x_t,x_0) = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}}\times \epsilon_{\theta}(x_t,t))</script><p>但这样我们只的到了一个确定的$\mu_{\theta}$，而本身这个过程是一个推算概率分布的过程，它具有不确定性，因此需要在高斯分布中再次采样，以保持采样过程的随机性，以生成不同的样本。</p>
<h2 id="重参数化"><a href="#重参数化" class="headerlink" title="重参数化"></a>重参数化</h2><p>现在我们指导反向过程还是高斯分布，我们便利用这个均值做一个标准正态采样</p>
<script type="math/tex; mode=display">x_{t-1} = \mu_{\theta}(x_t,t)+\sigma_tz~,~~~~z\sim N(0,1)</script><p>因此整合之后便得到了</p>
<script type="math/tex; mode=display">x_{t-1} = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}}\times \epsilon_{\theta}(x_t,t))+\sigma_{t}z</script><p>其中$\sigma_t=\widetilde{\beta}_t$ .</p>
<h1 id="复现代码"><a href="#复现代码" class="headerlink" title="复现代码"></a>复现代码</h1><p>以下是复现的代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import pandas as pd</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">from torchvision import datasets, transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line"></span><br><span class="line">def show_images(data, num_samples=16, cols=16):</span><br><span class="line">    plt.figure(figsize=(15, 15))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_samples):</span><br><span class="line">        img, label = data[i]  <span class="comment"># 获取图像和标签</span></span><br><span class="line">        img = img.permute(1, 2, 0).numpy()  <span class="comment"># (C, H, W) -&gt; (H, W, C)</span></span><br><span class="line">        plt.subplot(int(num_samples / cols + 1), cols, i + 1)</span><br><span class="line">        plt.imshow(img)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line">  </span><br><span class="line">root = <span class="string">&quot;/kaggle/input/cifar10-python&quot;</span></span><br><span class="line">  </span><br><span class="line">train_dataset = datasets.CIFAR10(root, train=True, download=True,transform=transforms.ToTensor())</span><br><span class="line">train_dataLoader = DataLoader(train_dataset, batch_size=3000, shuffle=True)</span><br><span class="line">test_dataset = datasets.CIFAR10(root, train=False, download=True,transform=transforms.ToTensor())</span><br><span class="line">test_dataLoader = DataLoader(test_dataset, batch_size=3000, shuffle=True)</span><br><span class="line">show_images(train_dataset)</span><br><span class="line">show_images(test_dataset)</span><br><span class="line">  </span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">  </span><br><span class="line">def linear_beta_schedule(timesteps, start=0.0001, end = 0.02):</span><br><span class="line">    <span class="built_in">return</span> torch.linspace(start, end, timesteps)</span><br><span class="line"><span class="comment">#根据时间步 t 从一个值列表 vals 中获取对应的值，并对输出形状进行 reshape 以匹配输入张量的维度结构 x_shape</span></span><br><span class="line">def get_index_from_list(vals, t, x_shape):</span><br><span class="line">    batch_size = t.shape[0]</span><br><span class="line">    out = vals.gather(-1, t.cpu())</span><br><span class="line">    <span class="built_in">return</span> out.reshape(batch_size, *((<span class="number">1</span>,)*(len(x_shape) - <span class="number">1</span>))).to(t.device)</span><br><span class="line"><span class="comment">#接受一个图像和一个时间步长作为输入，并返回它的噪声版本</span></span><br><span class="line">def forward_diffusion_sample(x_0, t ,device=device):</span><br><span class="line">    x_0.to(device)</span><br><span class="line">    noise = torch.randn_like(x_0)</span><br><span class="line">    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)</span><br><span class="line">    sqrt_one_minus_alphas_cumprod_t=get_index_from_list(sqrt_one_minus_alphas_cumprod, t, x_0.shape)</span><br><span class="line">    <span class="built_in">return</span> sqrt_alphas_cumprod_t.to(device)*x_0.to(device)\</span><br><span class="line">    +sqrt_one_minus_alphas_cumprod_t.to(device)*noise.to(device), noise.to(device)</span><br><span class="line">  </span><br><span class="line">T=300</span><br><span class="line">betas = linear_beta_schedule(timesteps=T)</span><br><span class="line">  </span><br><span class="line">alphas = 1.-betas</span><br><span class="line">alphas_cumprod = torch.cumprod(alphas, axis=0)</span><br><span class="line">alphas_cumprod_prev = F.pad(alphas_cumprod[:-1],(1,0),value=1.0)</span><br><span class="line">sqrt_recip_alphas= torch.sqrt(1.0/alphas)</span><br><span class="line">sqrt_alphas_cumprod=torch.sqrt(alphas_cumprod)</span><br><span class="line">sqrt_one_minus_alphas_cumprod = torch.sqrt(1.-alphas_cumprod)</span><br><span class="line">posterior_variance = betas * (1. - alphas_cumprod_prev)/(1. - alphas_cumprod)</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">import torch</span><br><span class="line">from torchvision import datasets, transforms</span><br><span class="line">from torch.utils.data import DataLoader</span><br><span class="line">import numpy as np</span><br><span class="line">  </span><br><span class="line">img_size = 64</span><br><span class="line">batch_size =128</span><br><span class="line">def load_transformed_dataset():</span><br><span class="line">    data_transforms=[</span><br><span class="line">        transforms.Resize((img_size,img_size)),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">        transforms.Lambda(lambda t:(t*2)-1)</span><br><span class="line">    ]</span><br><span class="line">    data_transform = transforms.Compose(data_transforms)</span><br><span class="line">    train = datasets.CIFAR10(root, train=True, download=True,transform=data_transform)</span><br><span class="line">    <span class="built_in">test</span> = datasets.CIFAR10(root, train=False, download=False,transform=data_transform)</span><br><span class="line">    <span class="built_in">return</span> torch.utils.data.ConcatDataset([train,<span class="built_in">test</span>])</span><br><span class="line">def show_tensor_image(image):</span><br><span class="line">    reverse_transforms = transforms.Compose([</span><br><span class="line">        transforms.Lambda(lambda t:(t+1)/2),</span><br><span class="line">        transforms.Lambda(lambda t:t.permute(1,2,0)),</span><br><span class="line">        transforms.Lambda(lambda t:t*255.),</span><br><span class="line">        transforms.Lambda(lambda t:t.cpu().numpy().astype(np.uint8)),</span><br><span class="line">        transforms.ToPILImage(),</span><br><span class="line">    ])</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> len(image.shape)==4:</span><br><span class="line">        image = image[0,:,:,:]</span><br><span class="line">    plt.imshow(reverse_transforms(image))</span><br><span class="line">root = <span class="string">&quot;/root/autodl-fs/cifar-10-python&quot;</span></span><br><span class="line">data = load_transformed_dataset()</span><br><span class="line">dataloader = DataLoader(data, batch_size, shuffle=True, drop_last=True)</span><br><span class="line">  </span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">image = next(iter(dataloader))[0]</span><br><span class="line">  </span><br><span class="line">plt.figure(figsize=(15,15))</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">num_images = 10</span><br><span class="line">stepsize = int(T/num_images)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> range(0, T, stepsize):</span><br><span class="line">    t = torch.Tensor([idx]).<span class="built_in">type</span>(torch.int64)</span><br><span class="line">    plt.subplot(1, num_images+1, int(idx/stepsize)+1)</span><br><span class="line">    image, noise = forward_diffusion_sample(image, t)</span><br><span class="line">    show_tensor_image(image)</span><br><span class="line">  </span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.savefig(<span class="string">&quot;diffusion_process.png&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Saved to diffusion_process.png&quot;</span>)</span><br><span class="line">  </span><br><span class="line">from torch import nn</span><br><span class="line">import math</span><br><span class="line">  </span><br><span class="line">class Block(nn.Module):</span><br><span class="line">    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.time_mlp = nn.Linear(time_emb_dim, out_ch)</span><br><span class="line">        <span class="keyword">if</span> up:</span><br><span class="line">            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)</span><br><span class="line">            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)</span><br><span class="line">            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)</span><br><span class="line">        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)</span><br><span class="line">        self.bnorm1 = nn.BatchNorm2d(out_ch)</span><br><span class="line">        self.bnorm2 = nn.BatchNorm2d(out_ch)</span><br><span class="line">        self.relu = nn.ReLU()</span><br><span class="line">  </span><br><span class="line">    def forward(self, x, t, ):</span><br><span class="line">        h = self.bnorm1(self.relu(self.conv1(x)))</span><br><span class="line">        time_emb = self.relu(self.time_mlp(t))</span><br><span class="line">        time_emb = time_emb[(..., )+(None, )*2]</span><br><span class="line">        h = h+time_emb</span><br><span class="line">        h = self.bnorm2(self.relu(self.conv2(h)))</span><br><span class="line">        <span class="built_in">return</span> self.transform(h)</span><br><span class="line">  </span><br><span class="line">class SinusoidalPositionEmbeddings(nn.Module):</span><br><span class="line">    def __init__(self, dim):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.dim = dim</span><br><span class="line">  </span><br><span class="line">    def forward(self, <span class="keyword">time</span>):</span><br><span class="line">        device = time.device</span><br><span class="line">        half_dim = self.dim //2</span><br><span class="line">        embeddings = math.log(10000)/(half_dim - 1)</span><br><span class="line">        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)</span><br><span class="line">        embeddings = <span class="keyword">time</span>[:,None]*embeddings[None, :]</span><br><span class="line">        embeddings = torch.cat((embeddings.sin(),embeddings.cos()), dim=1)</span><br><span class="line">        <span class="built_in">return</span> embeddings</span><br><span class="line">  </span><br><span class="line">class UNet(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        image_channels = 3</span><br><span class="line">        down_channels = (64, 128, 256, 512, 1024)</span><br><span class="line">        up_channels = (1024, 512, 256, 128, 64)</span><br><span class="line">        out_dim = 1</span><br><span class="line">        time_emb_dim = 32</span><br><span class="line">  </span><br><span class="line">        self.time_mlp = nn.Sequential(</span><br><span class="line">            SinusoidalPositionEmbeddings(time_emb_dim),</span><br><span class="line">            nn.Linear(time_emb_dim, time_emb_dim),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">            )</span><br><span class="line">  </span><br><span class="line">        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)</span><br><span class="line">        <span class="comment">#下采样</span></span><br><span class="line">        self.downs = nn.ModuleList([Block(down_channels[i],down_channels[i+1],time_emb_dim)\</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(down_channels)-1)])</span><br><span class="line">        <span class="comment">#上采样</span></span><br><span class="line">        self.ups = nn.ModuleList([Block(up_channels[i],up_channels[i+1],time_emb_dim,up=True)\</span><br><span class="line">                    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(down_channels)-1)])</span><br><span class="line">        self.output = nn.Conv2d(up_channels[-1], 3, out_dim)</span><br><span class="line">    def forward(self, x, timestep):</span><br><span class="line">        t=self.time_mlp(timestep)</span><br><span class="line">        t.to(x.device)</span><br><span class="line">        x=self.conv0(x)</span><br><span class="line">        residual_inputs = []</span><br><span class="line">        <span class="keyword">for</span> down <span class="keyword">in</span> self.downs:</span><br><span class="line">            x = down(x,t)</span><br><span class="line">            residual_inputs.append(x)</span><br><span class="line">        <span class="keyword">for</span> up <span class="keyword">in</span> self.ups:</span><br><span class="line">            residual_x = residual_inputs.pop()</span><br><span class="line">            x = torch.cat((x,residual_x),dim=<span class="number">1</span>)</span><br><span class="line">            x=up(x,t)</span><br><span class="line">        return self.output(x)</span><br><span class="line">  </span><br><span class="line">model = UNet()</span><br><span class="line">print(&quot;Num params:&quot;, sum(p.numel() for p in model.parameters()))</span><br><span class="line"></span><br><span class="line">def get_loss(model, x_0, t):</span><br><span class="line">    x_noisy, noise = forward_diffusion_sample(x_0, t, device)</span><br><span class="line">    noise_pred = model(x_noisy, t)</span><br><span class="line">    noise_pred.to(device)</span><br><span class="line">    <span class="built_in">return</span> F.l1_loss(noise, noise_pred)</span><br><span class="line">  </span><br><span class="line">@torch.no_grad()</span><br><span class="line">def sample_timestep(x,t):</span><br><span class="line">    betas_t = get_index_from_list(betas, t, x.shape)</span><br><span class="line">    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod,t,x.shape)</span><br><span class="line">    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)</span><br><span class="line">  </span><br><span class="line">    model_mean = sqrt_recip_alphas_t * (x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t)</span><br><span class="line">    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">if</span> t==0:</span><br><span class="line">        <span class="built_in">return</span> model_mean</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        noise = torch.randn_like(x)</span><br><span class="line">        <span class="built_in">return</span> model_mean + torch.sqrt(posterior_variance_t)*noise</span><br><span class="line">  </span><br><span class="line">@torch.no_grad()</span><br><span class="line">def sample_plot_image():</span><br><span class="line">    Img_size=img_size</span><br><span class="line">    img = torch.randn((<span class="number">1</span>, <span class="number">3</span>, Img_size, Img_size),device=device)</span><br><span class="line">    plt.figure(figsize=(<span class="number">15</span>,<span class="number">15</span>))</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    num_images=10</span><br><span class="line">    stepsize = int(T/num_images)</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(0,T)[::-1]:</span><br><span class="line">        t = torch.full((<span class="number">1</span>,), i, device=device, dtype=torch.long)</span><br><span class="line">        img = sample_timestep(img,t)</span><br><span class="line">        if i %stepsize ==<span class="number">0</span>:</span><br><span class="line">            plt.subplot(<span class="number">1</span>,num_images, int(i/stepsize+<span class="number">1</span>))</span><br><span class="line">            show_tensor_image(img.detach().cpu())</span><br><span class="line">  </span><br><span class="line">from torch.optim import Adam</span><br><span class="line">device = <span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span></span><br><span class="line">model.to(device)</span><br><span class="line">noise = noise.to(device)</span><br><span class="line">model = nn.DataParallel(model)</span><br><span class="line">optimizer = Adam(model.parameters(), lr=0.001)</span><br><span class="line">epochs = 100</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> enumerate(dataloader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        t = torch.randint(0,T,(batch_size,),device=device).long()</span><br><span class="line">        loss=get_loss(model, batch[0],t)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">  </span><br><span class="line">        <span class="keyword">if</span> epoch % 1 ==0 and step == 0:</span><br><span class="line">            <span class="built_in">print</span>(f<span class="string">&quot;Epoch&#123;epoch&#125; | step &#123;step:03d&#125; loss: &#123;loss.item()&#125;&quot;</span>)</span><br><span class="line">            sample_plot_image()</span><br><span class="line">            plt.tight_layout()</span><br><span class="line">            plt.savefig(f<span class="string">&quot;diffusion_process_&#123;epoch&#125;.png&quot;</span>)</span><br><span class="line">            <span class="built_in">print</span>(f<span class="string">&quot;Saved to diffusion_process_&#123;epoch&#125;.png&quot;</span>)</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/04/15/hello-world/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="B.W. Xiang">
      <meta itemprop="description" content="选择大于努力">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小象的知识库">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2025/04/15/hello-world/" class="post-title-link" itemprop="url">Hello World</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-04-15 20:50:48" itemprop="dateCreated datePublished" datetime="2025-04-15T20:50:48+08:00">2025-04-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">B.W. Xiang</p>
  <div class="site-description" itemprop="description">选择大于努力</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">2</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">B.W. Xiang</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>

        








      </div>
    </footer>
  </div>

  
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
